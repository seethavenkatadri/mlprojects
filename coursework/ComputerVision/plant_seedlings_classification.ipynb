{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9VXT5unCaBd"
   },
   "source": [
    "# Introduction to Computer Vision: Plant Seedlings Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZgcS1MyVGZp"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCxSmokWEKUJ"
   },
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2mC12JhVNGp"
   },
   "source": [
    "In recent times, the field of agriculture has been in urgent need of modernizing, since the amount of manual work people need to put in to check if plants are growing correctly is still highly extensive. Despite several advances in agricultural technology, people working in the agricultural industry still need to have the ability to sort and recognize different plants and weeds, which takes a lot of time and effort in the long term. The potential is ripe for this trillion-dollar industry to be greatly impacted by technological innovations that cut down on the requirement for manual labor, and this is where Artificial Intelligence can actually benefit the workers in this field, as **the time and energy required to identify plant seedlings will be greatly shortened by the use of AI and Deep Learning.** The ability to do so far more efficiently and even more effectively than experienced manual labor, could lead to better crop yields, the freeing up of human inolvement for higher-order agricultural decision making, and in the long term will result in more sustainable environmental practices in agriculture as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_I9gQJMVWL_"
   },
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkD5j4o4VYYQ"
   },
   "source": [
    "The aim of this project is to Build a Convolutional Neural Netowrk to classify plant seedlings into their respective categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZq8uFtOVfnm"
   },
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75fTG3prVjUU"
   },
   "source": [
    "The Aarhus University Signal Processing group, in collaboration with the University of Southern Denmark, has recently released a dataset containing **images of unique plants belonging to 12 different species.**\n",
    "\n",
    "- The dataset can be download from Olympus.\n",
    "- The data file names are:\n",
    "    - images.npy\n",
    "    - Labels.csv\n",
    "- Due to the large volume of data, the images were converted to the images.npy file and the labels are also put into Labels.csv, so that you can work on the data/project seamlessly without having to worry about the high data volume.\n",
    "\n",
    "- The goal of the project is to create a classifier capable of determining a plant's species from an image.\n",
    "\n",
    "**List of Species**\n",
    "\n",
    "- Black-grass\n",
    "- Charlock\n",
    "- Cleavers\n",
    "- Common Chickweed\n",
    "- Common Wheat\n",
    "- Fat Hen\n",
    "- Loose Silky-bent\n",
    "- Maize\n",
    "- Scentless Mayweed\n",
    "- Shepherds Purse\n",
    "- Small-flowered Cranesbill\n",
    "- Sugar beet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9B4COveVqnm"
   },
   "source": [
    "### **Note: Please use GPU runtime on Google Colab to execute the code faster.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqFzmTb0BKKW"
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.25.2 in /usr/local/anaconda3/lib/python3.11/site-packages (1.25.2)\n",
      "Collecting pandas==2.0.3\n",
      "  Using cached pandas-2.0.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: seaborn==0.13.1 in /Users/seethadixit/.local/lib/python3.11/site-packages (0.13.1)\n",
      "Requirement already satisfied: tensorflow==2.15.0 in /Users/seethadixit/.local/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in /Users/seethadixit/.local/lib/python3.11/site-packages (3.7.1)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv-python-4.10.0.84.tar.gz (95.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/anaconda3/lib/python3.11/site-packages (from pandas==2.0.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from pandas==2.0.3) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from pandas==2.0.3) (2023.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/seethadixit/.local/lib/python3.11/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorflow==2.15.0) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/seethadixit/.local/lib/python3.11/site-packages (from tensorflow==2.15.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/seethadixit/.local/lib/python3.11/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/seethadixit/.local/lib/python3.11/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.2.2) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.2.2) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from matplotlib==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/anaconda3/lib/python3.11/site-packages (from matplotlib==3.7.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from matplotlib==3.7.1) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from matplotlib==3.7.1) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from matplotlib==3.7.1) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from matplotlib==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/seethadixit/.local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/seethadixit/.local/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/seethadixit/.local/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
      "Using cached pandas-2.0.3-cp311-cp311-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "Building wheels for collected packages: opencv-python\n",
      "  Building wheel for opencv-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opencv-python: filename=opencv_python-4.10.0.84-cp311-cp311-macosx_10_16_x86_64.whl size=27675946 sha256=0c84289e1153eac47b245e0841c34c10b303da435110b6f0ce124c73936fadbe\n",
      "  Stored in directory: /Users/seethadixit/Library/Caches/pip/wheels/16/15/c8/aaf845de30a73df1a8a672bd9a27f5f2c62f8631fd54034492\n",
      "Successfully built opencv-python\n",
      "Installing collected packages: opencv-python, pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.4\n",
      "    Uninstalling pandas-2.1.4:\n",
      "      Successfully uninstalled pandas-2.1.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyfume 0.3.4 requires numpy==1.24.4, but you have numpy 1.25.2 which is incompatible.\n",
      "pyfume 0.3.4 requires pandas==1.5.3, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed opencv-python-4.10.0.84 pandas-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy==1.25.2 pandas==2.0.3 seaborn==0.13.1 tensorflow==2.15.0 scikit-learn==1.2.2 matplotlib==3.7.1 opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FsytN_Rps2Cz"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m                                                                  \u001b[38;5;66;03m# Importting matplotlib for Plotting and visualizing images\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m                                                                                      \u001b[38;5;66;03m# Importing math module to perform mathematical operations\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m                                                                                       \u001b[38;5;66;03m# Importing openCV for image processing\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m                                                                            \u001b[38;5;66;03m# Importing seaborn to plot graphs\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Tensorflow modules\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np                                                                               # Importing numpy for Matrix Operations\n",
    "import pandas as pd                                                                              # Importing pandas to read CSV files\n",
    "import matplotlib.pyplot as plt                                                                  # Importting matplotlib for Plotting and visualizing images\n",
    "import math                                                                                      # Importing math module to perform mathematical operations\n",
    "import cv2                                                                                       # Importing openCV for image processing\n",
    "import seaborn as sns                                                                            # Importing seaborn to plot graphs\n",
    "\n",
    "\n",
    "# Tensorflow modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator                              # Importing the ImageDataGenerator for data augmentation\n",
    "from tensorflow.keras.models import Sequential                                                   # Importing the sequential module to define a sequential model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D,BatchNormalization # Defining all the layers to build our CNN Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD                                                 # Importing the optimizers which can be used in our model\n",
    "from sklearn import preprocessing                                                                # Importing the preprocessing module to preprocess the data\n",
    "from sklearn.model_selection import train_test_split                                             # Importing train_test_split function to split the data into train and test\n",
    "from sklearn.metrics import confusion_matrix                                                     # Importing confusion_matrix to plot the confusion matrix\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oq-hAEOAV4aZ"
   },
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XztFCIActAb"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run the below code if you are using google colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2q2QUVZtpFb"
   },
   "outputs": [],
   "source": [
    "# Load the image file of the dataset\n",
    "images = np.load('images.npy')\n",
    "\n",
    "# Load the labels file of the dataset\n",
    "labels = pd.read_csv('Labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uE84hQU7CSZa"
   },
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57vwo75fcXbU"
   },
   "source": [
    "### Understand the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2F57JGGcbzz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYv5uX-MC9KC"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf_sWYNOjDvK"
   },
   "source": [
    "- EDA is an important part of any project involving data.\n",
    "- It is important to investigate and understand the data better before building a model with it.\n",
    "- A few questions have been mentioned below which will help you understand the data better.\n",
    "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4dZsdgujrtK"
   },
   "source": [
    "1. How are these different category plant images different from each other?\n",
    "2. Is the dataset provided an imbalance? (Check with using bar plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxTvixIeBVIq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOvazq-OWpNB"
   },
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzpcKHaDWsG7"
   },
   "source": [
    "### Convert the BGR images to RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9u82V2TWsuQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STMonBqiWxM5"
   },
   "source": [
    "### Resize the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pESDU0AEMOFk"
   },
   "source": [
    "As the size of the images is large, it may be computationally expensive to train on these larger images; therefore, it is preferable to reduce the image size from 128 to 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJYZ4IpGkwre"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdsVQb4umB0P"
   },
   "source": [
    "### Data Preparation for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KljdsjFCmJIZ"
   },
   "source": [
    "- Before you proceed to build a model, you need to split the data into train, test, and validation to be able to evaluate the model that you build on the train data\n",
    "- You'll have to encode categorical features and scale the pixel values.\n",
    "- You will build a model using the train data and then check its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQV0unTvM7XM"
   },
   "source": [
    "**Split the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USifnEb_m85i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAJ9B0wKNiY3"
   },
   "source": [
    "### Encode the target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88OIAwNoEPfx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exJFCDSMNrEG"
   },
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVUuPJS9OB_U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9_M19L-OLng"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0fnV8yNKmYr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNKUalx8Jcoi"
   },
   "source": [
    "## Model Performance Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_oS4D_AXFqX"
   },
   "source": [
    "**Reducing the Learning Rate:**\n",
    "\n",
    "**Hint**: Use **ReduceLRonPlateau()** function that will be used to decrease the learning rate by some factor, if the loss is not decreasing for some time. This may start decreasing the loss at a smaller learning rate. There is a possibility that the loss may still not decrease. This may lead to executing the learning rate reduction again in an attempt to achieve a lower loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU6vqL67bd5a"
   },
   "source": [
    "### **Data Augmentation**\n",
    "\n",
    "Remember, **data augmentation should not be used in the validation/test data set**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5cgkAz_YKcc"
   },
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3MjkGfHYOPn"
   },
   "source": [
    "Comment on the final model you have selected and use the same in the below code to visualize the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IESvQ8UyYLSK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvDkLMO7YIdY"
   },
   "source": [
    "### Visualizing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iez7QKJBrHvE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg2x8AyJ4oPR"
   },
   "source": [
    "## Actionable Insights and Business Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvq4_6CZYcrv"
   },
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geC4LwwIYfS_"
   },
   "source": [
    "_____"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4ZgcS1MyVGZp",
    "WCxSmokWEKUJ",
    "q_I9gQJMVWL_",
    "aZq8uFtOVfnm",
    "qqFzmTb0BKKW",
    "oq-hAEOAV4aZ",
    "uE84hQU7CSZa",
    "57vwo75fcXbU",
    "EYv5uX-MC9KC",
    "vOvazq-OWpNB",
    "hzpcKHaDWsG7",
    "STMonBqiWxM5",
    "LdsVQb4umB0P",
    "FAJ9B0wKNiY3",
    "exJFCDSMNrEG",
    "d9_M19L-OLng",
    "kNKUalx8Jcoi",
    "A5cgkAz_YKcc",
    "Eg2x8AyJ4oPR"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
